{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Data Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Jonathan Cheung\n",
    "- Joshua Chuang\n",
    "- Joyce Hu\n",
    "- Ester Tsai\n",
    "- Sam Wong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='research_question'></a>\n",
    "# Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For American films, are information like genre, release year, duration, director, production company, and textual analysis of the film's plot on Wikipedia correlated with its box office sales?\n",
    "\n",
    "Is there a correlation between genre, release year, duration, director, production company, and textual analysis of Wikipedia plots for box office sales of American films? \n",
    "\n",
    "Which factor, among factors such as director, production company, genre, and duration, has the most impact on an American film's box office sale?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dataset Name: \"American Films.csv\"\n",
    "- Link to the dataset: Web scraped from Wikipedia\n",
    "- Number of observations:\n",
    "\n",
    "This dataset was scraped from the Wikipeida page \"American Films by Genre\" (https://en.wikipedia.org/wiki/Category:American_films_by_genre). It contains the variables 'Film name', 'Genre', 'Plot', 'Directed by', 'Written by', 'Story by', 'Produced by', 'Starring', 'Cinematography', 'Edited by', 'Music by', 'Production company', 'Distributed by', 'Release date', 'Running time', 'Budget', and 'Box office'. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\tsaie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\tsaie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Pandas and numpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Data visualization\n",
    "import seaborn as sns\n",
    "sns.set(font_scale=2, style=\"white\")\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as style\n",
    "\n",
    "# set plotting size parameter\n",
    "plt.rcParams['figure.figsize'] = (12, 5)\n",
    "\n",
    "# Webscraping\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Textual and sentiment analysis\n",
    "import re\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from LeXmo import LeXmo\n",
    "\n",
    "\n",
    "# Improve resolution\n",
    "%config InlineBackend.figure_format ='retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Data Overview / Final Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Data Collection\n",
    "### Specify the URLs to scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_link = {\n",
    "    'Action': [\n",
    "        'https://en.wikipedia.org/w/index.php?title=Category:American_action_films&pageuntil=Driving+Force+%281989+film%29#mw-pages',\n",
    "        'https://en.wikipedia.org/w/index.php?title=Category:American_action_films&pagefrom=Driving+Force+%281989+film%29#mw-pages',\n",
    "        'https://en.wikipedia.org/w/index.php?title=Category:American_action_films&pagefrom=Marksman%2C+The%0AThe+Marksman+%282005+film%29#mw-pages',\n",
    "        'https://en.wikipedia.org/w/index.php?title=Category:American_action_films&pagefrom=Spider-Man+3#mw-pages'\n",
    "    ]\n",
    "    ,\n",
    "    'Crime': [\n",
    "        'https://en.wikipedia.org/wiki/Category:American_crime_films',\n",
    "        'https://en.wikipedia.org/w/index.php?title=Category:American_crime_films&pagefrom=Dial+Red+O#mw-pages',\n",
    "        'https://en.wikipedia.org/w/index.php?title=Category:American_crime_films&pagefrom=Ivy+%28Film%29%0AIvy+%281947+film%29#mw-pages',\n",
    "        'https://en.wikipedia.org/w/index.php?title=Category:American_crime_films&pagefrom=One+Stolen+Night+%281929+film%29#mw-pages',\n",
    "        'https://en.wikipedia.org/w/index.php?title=Category:American_crime_films&pagefrom=Tenderloin+%28film%29#mw-pages'\n",
    "    ]\n",
    "    ,\n",
    "    'War': [\n",
    "        'https://en.wikipedia.org/wiki/Category:American_war_films',\n",
    "        'https://en.wikipedia.org/w/index.php?title=Category:American_war_films&pagefrom=Retreat%2C+Hell%21#mw-pages'\n",
    "    ]\n",
    "    ,\n",
    "    'Romance': [\n",
    "        'https://en.wikipedia.org/wiki/Category:American_romance_films',\n",
    "        'https://en.wikipedia.org/w/index.php?title=Category:American_romance_films&pagefrom=Sporting+Venus%2C+The%0AThe+Sporting+Venus#mw-pages'\n",
    "    ]\n",
    "    ,\n",
    "    'Thriller': [\n",
    "        'https://en.wikipedia.org/wiki/Category:American_thriller_films',\n",
    "        'https://en.wikipedia.org/w/index.php?title=Category:American_thriller_films&pagefrom=Godsend+%282004+film%29#mw-pages',\n",
    "        'https://en.wikipedia.org/w/index.php?title=Category:American_thriller_films&pagefrom=Poltergeist+%28film%29%0APoltergeist+%281982+film%29#mw-pages',\n",
    "        'https://en.wikipedia.org/w/index.php?title=Category:American_thriller_films&pagefrom=Winchester+%28film%29#mw-pages'\n",
    "    ]\n",
    "    ,\n",
    "    'Horror': [\n",
    "        'https://en.wikipedia.org/wiki/Category:American_horror_films',\n",
    "        'https://en.wikipedia.org/w/index.php?title=Category:American_horror_films&pagefrom=Isle+of+the+Dead+%28film%29#mw-pages',\n",
    "        'https://en.wikipedia.org/w/index.php?title=Category:American_horror_films&pagefrom=West+of+Hell#mw-pages'\n",
    "    ]\n",
    "    ,\n",
    "    'Biographical': [\n",
    "        'https://en.wikipedia.org/wiki/Category:American_biographical_films',\n",
    "        'https://en.wikipedia.org/w/index.php?title=Category:American_biographical_films&pagefrom=I+Wanna+Dance+with+Somebody+%28film%29#mw-pages',\n",
    "        'https://en.wikipedia.org/w/index.php?title=Category:American_biographical_films&pagefrom=Story+of+Alexander+Graham+Bell%0AThe+Story+of+Alexander+Graham+Bell#mw-pages'\n",
    "    ]\n",
    "    ,\n",
    "    'Satirical': [\n",
    "        'https://en.wikipedia.org/wiki/Category:American_satirical_films',\n",
    "        'https://en.wikipedia.org/w/index.php?title=Category:American_satirical_films&pagefrom=Hospital%2C+The%0AThe+Hospital#mw-pages',\n",
    "        'https://en.wikipedia.org/w/index.php?title=Category:American_satirical_films&pagefrom=Taintlight%0ATaintlight#mw-pages'\n",
    "    ]\n",
    "    ,\n",
    "    'Science Fiction': [\n",
    "        'https://en.wikipedia.org/wiki/Category:American_science_fiction_films',\n",
    "        'https://en.wikipedia.org/w/index.php?title=Category:American_Western_(genre)_films&pagefrom=Big+Sombrero%2C+The%0AThe+Big+Sombrero+%28film%29#mw-pages'\n",
    "    ]\n",
    "    ,\n",
    "    'Monster': [\n",
    "        'https://en.wikipedia.org/wiki/Category:American_monster_movies',\n",
    "        'https://en.wikipedia.org/w/index.php?title=Category:American_monster_movies&pagefrom=Fly%2C+The%0AThe+Fly+%281986+film%29#mw-pages',\n",
    "        'https://en.wikipedia.org/w/index.php?title=Category:American_monster_movies&pagefrom=Nailbiter#mw-pages',\n",
    "        'https://en.wikipedia.org/w/index.php?title=Category:American_monster_movies&pagefrom=World+Without+End+%28film%29#mw-pages'\n",
    "    ]\n",
    "    ,\n",
    "    'Mystery': [\n",
    "        'https://en.wikipedia.org/wiki/Category:American_mystery_films',\n",
    "        'https://en.wikipedia.org/w/index.php?title=Category:American_mystery_films&pagefrom=Deceiver+%28film%29#mw-pages',\n",
    "        'https://en.wikipedia.org/w/index.php?title=Category:American_mystery_films&pagefrom=House+of+Fear%2C+The%0AThe+House+of+Fear+%281915+film%29#mw-pages',\n",
    "        'https://en.wikipedia.org/w/index.php?title=Category:American_mystery_films&pagefrom=Murder+She+Baked%0AMurder%2C+She+Baked#mw-pages',\n",
    "        'https://en.wikipedia.org/w/index.php?title=Category:American_mystery_films&pagefrom=Seven+Footprints+To+Satan+%28Film%29%0ASeven+Footprints+to+Satan#mw-pages',\n",
    "        'https://en.wikipedia.org/w/index.php?title=Category:American_mystery_films&pagefrom=X+Marks+The+Spot%0AX+Marks+the+Spot+%281942+film%29#mw-pages'\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify the additional information to include \n",
    "Note: The film name, genre, and plot are already included in the final dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_list = [\n",
    "    'Film name', \n",
    "    'Genre', \n",
    "    'Plot',\n",
    "    'Directed by',\n",
    "    'Written by',\n",
    "    'Story by',\n",
    "    'Produced by',\n",
    "    'Starring',\n",
    "    'Cinematography',\n",
    "    'Edited by',\n",
    "    'Music by',\n",
    "    'Production company',\n",
    "    'Distributed by',\n",
    "    'Release date',\n",
    "    'Running time',\n",
    "    'Budget',\n",
    "    'Box office'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web scrape Wikipedia and construct dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a blank dataframe and assign column names\n",
    "df = pd.DataFrame(columns=info_list)\n",
    "\n",
    "# Loop through the genres\n",
    "# category_links is a list of URLs for the same genre, but each URL contains around 200 individual films\n",
    "for genre, category_links in genre_link.items():\n",
    "    \n",
    "    # Each movie genre has several URLs since not everything can fit on the same page\n",
    "    # Loop through the URLs in category_links to access all the URLs for each movie genre\n",
    "    for category_link in category_links:\n",
    "        req = requests.get(category_link, timeout=50)\n",
    "        soup = BeautifulSoup(req.content, 'html') # get contents of web page    \n",
    "        \n",
    "        soup.find('div', {'class': 'mw-content-ltr'}).find_all('a', href=True)\n",
    "        \n",
    "        # Each category_link has around 200 individual films' URLs\n",
    "        # This for loop populates name_links dictionary with the film name as key and Wikipedia page URL as value\n",
    "        name_links = {}\n",
    "        for a in soup.find('div', {'class': 'mw-content-ltr'}).find_all('a', href=True):\n",
    "            film_name = a.text\n",
    "            link_end = a['href']\n",
    "            link = 'https://en.wikipedia.org' + link_end\n",
    "            if 'Categor' not in link: # skip if 'Category' or 'Categorization' is in the link\n",
    "                name_links[film_name] = link\n",
    "        \n",
    "        # Loop through the individual films' URLs to extract wanted info\n",
    "        for film_name, link in name_links.items():\n",
    "            req = requests.get(link, timeout=50)\n",
    "            soup = BeautifulSoup(req.content, 'html') # get contents of web page\n",
    "            tag_contents = soup.select('p, span.mw-headline')\n",
    "            \n",
    "            # Extract the plot (can also be named \"Premise\" or \"Synopsis\") if it exists\n",
    "            start_index_of_plot = -1\n",
    "            end_index_of_plot = -1\n",
    "            plot_exists = False\n",
    "\n",
    "            for i, tag_content in enumerate(tag_contents):\n",
    "                tag = tag_content.name\n",
    "                content = tag_content.text\n",
    "\n",
    "                if (plot_exists) & (tag == 'span'):\n",
    "                    end_index_of_plot = i\n",
    "                    break\n",
    "\n",
    "                if (content == 'Plot') | (content == 'Premise') | (content == 'Synopsis'):\n",
    "                    start_index_of_plot = i + 1\n",
    "                    plot_exists = True\n",
    "\n",
    "            plot = []\n",
    "            for content in tag_contents[start_index_of_plot: end_index_of_plot]:\n",
    "                par = content.text\n",
    "                plot += [par]\n",
    "\n",
    "            plot = \"\".join(plot).strip()\n",
    "            \n",
    "            # If plot exists, extract other info as well\n",
    "            if len(plot) >= 1:\n",
    "                \n",
    "                film_dict = {'Film name': film_name, 'Genre': genre, 'Plot': plot}\n",
    "                \n",
    "                # Get other info on the film, if the info table eixsts \n",
    "                try:\n",
    "                    req = requests.get(link, timeout=50)\n",
    "                    soup = BeautifulSoup(req.content, 'html')\n",
    "                    wiki_tables = soup.select('table', {'class': 'infobox vevent'})\n",
    "                    wiki_table = wiki_tables[0] # get info table\n",
    "\n",
    "                    # Loop through the tables until we have the info table we want\n",
    "                    i = 0\n",
    "                    while 'Directed by' not in wiki_table.text:\n",
    "                        i += 1\n",
    "                        wiki_table = wiki_tables[i]\n",
    "\n",
    "                    # Some minor data cleaning\n",
    "                    table_html = str(wiki_table).replace('<br/>', '/ ').replace('</li>', '/ ')\n",
    "                    table_html = re.sub(r\"\\[\\d+\\]\", \"\", table_html) # remove brackets (which provide link to references, but are not needed for our project)\n",
    "\n",
    "                    # Use pd.read_html to create pandas dataframe of the info table\n",
    "                    df = pd.read_html(table_html) \n",
    "                    df = pd.DataFrame(df[0]) # convert list to dataframe\n",
    "                    df.columns = ['col_name', 'info']\n",
    "                    df['col_name'] = df['col_name'].replace('/', ' ').replace('companies', 'company').replace('dates', 'date') # fix minor style error\n",
    "                    df['info'] = df['info'].apply(lambda x: x[:-1] if str(x)[-1] == \"/\" else x) # fix minor style error\n",
    "\n",
    "                    info_dict = {k: v for (k, v) in zip(list(df['col_name']), list(df['info'])) if k in info_list}\n",
    "                    dict_to_append = {**film_dict, **info_dict}\n",
    "                    \n",
    "                # If the info table does not exist, then only append the film name, genre, and plot\n",
    "                except:\n",
    "                    dict_to_append = film_dict\n",
    "                \n",
    "                # Update the dataframe\n",
    "                df = df.append(dict_to_append, ignore_index=True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Clean and Prepare the Dataset for Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove extra symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove references from 'Plot' column              \n",
    "df['Plot'] = df['Plot'].replace(r'\\[\\d+\\]','', regex=True).replace(r'\\[\\w\\]','', regex=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correct typos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.at[2753, 'Running time'] = '18 minutes'\n",
    "df.at[1277, 'Running time'] = '7 minutes'\n",
    "df.at[1189, 'Running time'] = '6 minutes'\n",
    "df.at[942, 'Running time'] = '1 minute'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract numerical info from text variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Duration (min)' extracts the number of minutes from 'Running time'\n",
    "df['Duration (min)'] = df['Running time'].str.lower().str.extract(r'(?P<duration>[\\d]+) min')\n",
    "\n",
    "# 'Release year' extracts the year from 'Release date'\n",
    "df['Release year'] = df['Release date'].str.extract(r'(\\d{4})')\n",
    "\n",
    "# 'Box office (mil)' extracts the dollar value in millions from 'Box office'\n",
    "def get_box_office_million_dollar(string):\n",
    "    if (type(string) != str) or ('$' not in string):\n",
    "        return np.nan\n",
    "    \n",
    "    string = string.replace(',', '').replace('$', '')\n",
    "    num = float(re.findall(r'(\\d+\\.?\\d*)', string)[0])\n",
    "    \n",
    "    if \"mil\" in string:\n",
    "        return num\n",
    "    else:\n",
    "        return num / 1_000_000\n",
    "\n",
    "df['Box office (mil)'] = df['Box office'].apply(get_box_office_million_dollar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VADER Sentiment Analysis\n",
    "\n",
    "VADER_SentimentIntensityAnalyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_VADER_sentiment(text):\n",
    "    return VADER_SentimentIntensityAnalyzer.polarity_scores(text)['compound']\n",
    "\n",
    "df['VADER Sentiment'] = df['Plot'].apply(get_VADER_sentiment)\n",
    "\n",
    "\n",
    "\n",
    "# Textblob Polarity and Subjectivity Analysis\n",
    "\n",
    "def get_TextBlob_subjectivity(text):\n",
    "    return TextBlob(text).sentiment.subjectivity\n",
    "\n",
    "def get_TextBlob_polarity(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "df['TextBlob Subjectivity'] = df['Plot'].apply(get_TextBlob_subjectivity)\n",
    "df['TextBlob Polarity'] = df['Plot'].apply(get_TextBlob_polarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
